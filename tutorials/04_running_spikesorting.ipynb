{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "509027b4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Running **spike sorting** pipelines:\n",
    "\n",
    "A spike sorting pipeline for neuropixels should consist of:\n",
    "\n",
    " - preprocessing (phase_shifting, filtering, denoising..)\n",
    " - motion correction\n",
    " - the actual sorting (assigning spikes to units)\n",
    " - waveform extraction\n",
    " - metric computation\n",
    "\n",
    "and some other optional steps like reading __sycnchronization channels__, __manual curation__ and result inspection.\n",
    "\n",
    "### ecephys spike sorting\n",
    "\n",
    "Check the usage instructions [**here**](https://github.com/jenniferColonell/ecephys_spike_sorting#usage).\n",
    "\n",
    "__ecephys__ is installed on the _course computers_; the instalation instructions are [**here**](https://github.com/jenniferColonell/ecephys_spike_sorting#installation-with-anaconda-and-kilosort4); don't forget to install _CatGT_ and set the paths in the ``ecephys_spike_sorting\\ecephys_spike_sorting\\scripts\\create_input_json.py`` file if you are installing from scratch. \n",
    "\n",
    "---\n",
    "\n",
    "To **configure** the pipeline you need to edit the file ``sglx_multi_run_pipeline.py`` in the ``ecephys_spike_sorting\\ecephys_spike_sorting\\scripts`` directory.\n",
    "\n",
    "In the _course computers_ that file is in: ``C:\\Users\\<USERNAME>\\ecephys_spike_sorting\\ecephys_spike_sorting\\scripts`` or ``C:\\ecephys_spike_sorting\\ecephys_spike_sorting\\scripts``\n",
    "\n",
    "The file (**sglx_multi_run_pipeline.py**) controls most aspects of the pipeline. Some things to check:\n",
    " 1. __line 67__: ``npx_directory = r'<PATH TO THE DATA FOLDER>'`` point to the directory to run\n",
    " 2. __line 91 to 93__: ``run_specs = [['<FILEPART NAME BEFORE THE GATE WITHOUT UNDERSCORE`, '<GATE NUMBER', '0,0', '0', '0', ['cortex','thalamus','thalamus'] ]``  specifies the file and gate to run, add multiple lines to concatenate gates or sessions\n",
    "\n",
    " 3. _optional:_ __line 106__: ``catGT_dest = r'<PATH TO AN EMPTY FOLDER>'`` don't forget to create the folder. this is the output path.\n",
    " 4. _optional_ __line 212__: ``json_directory = r'<PATH TO THE OUTPUT WHERE TO STORE JSON FILES>'`` this can be the same folder as point 3 or another if you want the files to be separate.\n",
    "\n",
    "---\n",
    "\n",
    "To **run**:\n",
    " - open a terminal where you can run conda commands. \n",
    " - activate the environment ``conda activate ks4_ece`` _in the course_.\n",
    " - go to the folder that has the ``sglx_multi_run_pipeline.py`` file using ``cd <FOLDERPATH>``\n",
    " - run the pipeline ``python sglx_multi_run_pipeline.py``\n",
    "\n",
    "\n",
    " ---\n",
    "\n",
    " To **visualize** the results:\n",
    "\n",
    "You can visualize with [**phy**](https://github.com/cortex-lab/phy).\n",
    "\n",
    " - open a terminal where you can run conda commands. \n",
    " - activate the environment ``conda activate phy2`` _in the course_.\n",
    " - go to the output folder using ``cd <FOLDERPATH>`` you want the folder that has the **params.py** file.\n",
    " - open phy using the command **``phy template-gui params.py``**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06089076",
   "metadata": {},
   "source": [
    "### Spike Interface pipeline for neuropixels\n",
    "\n",
    "Check the instructions [**here**](https://spikeinterface.readthedocs.io/en/0.93.0/overview.html).\n",
    "\n",
    "__spikeinterface__ is installed on the _course computers_; the instalation instructions are [**here**](https://spikeinterface.readthedocs.io/en/0.93.0/installation.html).\n",
    "\n",
    "Be sure to checkout the other [tutorials](https://spikeinterface.readthedocs.io/en/0.93.0/getting_started/plot_getting_started.html#).\n",
    "\n",
    "---\n",
    "\n",
    "We will build and run a pipeline on this notebook, it is based on the [how to guide](https://spikeinterface.readthedocs.io/en/latest/how_to/analyze_neuropixels.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733935a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.full as si\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# parameters\n",
    "FREQ_LOW = 300 # Frequency of the bandpass filter\n",
    "ks4_params = si.get_default_sorter_params('kilosort4')\n",
    "ks4_params['do_CAR'] = False # skip CAR in kilosort\n",
    "job_kwargs = dict(n_jobs=-1, chunk_duration='1s', progress_bar=True) # how to chunk and process data\n",
    "\n",
    "# specify the folder\n",
    "base_folder = Path(r'C:\\data\\invivo_demo')\n",
    "spikeglx_folder = base_folder/ 'NP24_demo_g0'\n",
    "# load spikeglx\n",
    "stream_names, stream_ids = si.get_neo_streams('spikeglx', spikeglx_folder)\n",
    "\n",
    "print(f'There are streams {stream_names} in folder {spikeglx_folder}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e55cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'All Kilosort4 parameters are: ')\n",
    "for k in ks4_params.keys():\n",
    "    print(f'   - {k}: {ks4_params[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093f0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets sort all 'ap streams'\n",
    "for stream in stream_names:\n",
    "    if not stream.endswith('.ap'):\n",
    "        continue    \n",
    "    raw_rec = si.read_spikeglx(spikeglx_folder, stream_name=stream_names, load_sync_channel=False)\n",
    "    # frequency filter\n",
    "    rec1 = si.highpass_filter(raw_rec, freq_min=FREQ_LOW)\n",
    "    bad_channel_ids, channel_labels = si.detect_bad_channels(rec1)\n",
    "    rec2 = rec1.remove_channels(bad_channel_ids)\n",
    "    print('bad_channel_ids', bad_channel_ids)\n",
    "    # phase shift\n",
    "    rec3 = si.phase_shift(rec2)\n",
    "    # CAR\n",
    "    rec = si.common_reference(rec3, operator=\"median\", reference=\"global\")\n",
    "    # save to disk\n",
    "    rec = rec.save(folder=base_folder / 'preprocess', format='binary', **job_kwargs)\n",
    "    sort_folder = base_folder / 'kilosort4_output'\n",
    "    # run ks4\n",
    "    sorting = si.run_sorter('kilosort4', rec, folder=sort_folder,\n",
    "                        docker_image=False, verbose=True, **ks4_params)\n",
    "    sorting = si.read_sorter_folder(sort_folder)\n",
    "\n",
    "    analyzer = si.create_sorting_analyzer(sorting, rec, sparse=True, format=\"memory\")\n",
    "    # compute waveforms \n",
    "    analyzer.compute(\"random_spikes\", method=\"uniform\", max_spikes_per_unit=500)\n",
    "    analyzer.compute(\"waveforms\",  ms_before=1.5,ms_after=1.5., **job_kwargs)\n",
    "    analyzer.compute(\"templates\", operators=[\"average\", \"median\", \"std\"])\n",
    "    analyzer.compute(\"noise_levels\")\n",
    "    analyzer.compute(\"correlograms\")\n",
    "    analyzer.compute(\"unit_locations\")\n",
    "    analyzer.compute(\"spike_amplitudes\", **job_kwargs)\n",
    "    # save\n",
    "    analyzer_saved = analyzer.save_as(folder=base_folder / \"analyzer\", format=\"binary_folder\")\n",
    "\n",
    "    metric_names=['firing_rate', 'presence_ratio', 'snr', 'isi_violation', 'amplitude_cutoff']\n",
    "    metrics = si.compute_quality_metrics(analyzer, metric_names=metric_names)\n",
    "    from spikeinterface.exporters import export_to_phy\n",
    "    export_to_phy(sorting_analyzer=analyzer, output_folder=base_folder/'phy_output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spikeinterface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
